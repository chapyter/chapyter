{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305f5dfc-d2e5-44eb-b6b5-4850e86274f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this notebook is based on the following study\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0dd73c65-10b2-41c9-9b56-2da33223224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# make sure changes in code take place immediately\n",
    "# this is a developer setting, don't need it for production\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "%reload_ext chapyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a23821b-301f-4402-8454-a0b74f531328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NOTEBOOK_NAME\"] = \"Harutyunyan_4tests_Sept29-Copy1.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee1d39-4e92-45fc-9868-0461a99c8542",
   "metadata": {},
   "source": [
    "## Let the study begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53ffd22-19ba-4df5-b8a2-6525907b49e6",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n"
     ]
    }
   ],
   "source": [
    "%%mimicSQL\n",
    "\n",
    "How can I join patients and chartevents tables in MIMIC-III?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211fbe3b-dbb9-485a-bbaf-8e6acf836fb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrunSQL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT *\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM patients p\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mJOIN chartevents c\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mON p.subject_id = c.subject_id\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/startup/mocha/code/sept25/chapyterMed/chapyter/magic.py:590\u001b[0m, in \u001b[0;36mChapyter.runSQL\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    587\u001b[0m current_message \u001b[38;5;241m=\u001b[39m cell\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m#retrieve the df, and put it in notebook memory\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m df, _ \u001b[38;5;241m=\u001b[39m \u001b[43msql_query_to_athena_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[0;32m~/Documents/startup/mocha/code/sept25/chapyterMed/chapyter/athena_utils.py:56\u001b[0m, in \u001b[0;36msql_query_to_athena_df\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQueryExecution\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCEEDED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCANCELLED\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQueryExecution\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCEEDED\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%runSQL \n",
    "\n",
    "\n",
    "SELECT *\n",
    "FROM patients p\n",
    "JOIN chartevents c\n",
    "ON p.subject_id = c.subject_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b8658-8117-4ceb-a60a-b51cee863813",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicSQL\n",
    "\n",
    "Great, lets create a table that joins them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6dd9-fa2c-4539-8bd9-110b970ffd91",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicSQL\n",
    "\n",
    "same thing, but include icustay, as well as chart events for\n",
    "\n",
    "1. Capillary refill rate\n",
    "2. Diastolic blood pressure\n",
    "3. Fraction inspired oxygen\n",
    "4. Glascow coma scale eye opening\n",
    "5. Glascow coma scale motor response\n",
    "6. Glascow coma scale total\n",
    "7. Glascow coma scale verbal response\n",
    "8. Glucose\n",
    "9. Heart Rate\n",
    "10. Height\n",
    "11. Mean blood pressure\n",
    "12. Oxygen saturation\n",
    "13. Respiratory rate\n",
    "14. Systolic blood pressure\n",
    "15. Temperature\n",
    "16. Weight\n",
    "17. pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3368ba5a-ce02-4f82-a096-396af3ecae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** # %%mimicRevealChatHistory --- # Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 400 tokens!\n"
     ]
    }
   ],
   "source": [
    "%%mimicRevealChatHistory\n",
    "\n",
    "Reveal all of these tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12325fa-a10e-46d2-a180-033fde6e54c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667</td>\n",
       "      <td>277996</td>\n",
       "      <td>618</td>\n",
       "      <td>2123-08-27 04:00:00.000</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>667</td>\n",
       "      <td>277996</td>\n",
       "      <td>456</td>\n",
       "      <td>2123-08-27 04:00:00.000</td>\n",
       "      <td>62.666698455810547</td>\n",
       "      <td>62.66669845581055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>667</td>\n",
       "      <td>277996</td>\n",
       "      <td>211</td>\n",
       "      <td>2123-08-27 04:00:00.000</td>\n",
       "      <td>83</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>667</td>\n",
       "      <td>277996</td>\n",
       "      <td>807</td>\n",
       "      <td>2123-08-27 03:00:00.000</td>\n",
       "      <td>112</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>667</td>\n",
       "      <td>277996</td>\n",
       "      <td>678</td>\n",
       "      <td>2123-08-27 03:00:00.000</td>\n",
       "      <td>97.800003051757812</td>\n",
       "      <td>97.80000305175781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id icustay_id itemid                charttime               value  \\\n",
       "0        667     277996    618  2123-08-27 04:00:00.000                  17   \n",
       "1        667     277996    456  2123-08-27 04:00:00.000  62.666698455810547   \n",
       "2        667     277996    211  2123-08-27 04:00:00.000                  83   \n",
       "3        667     277996    807  2123-08-27 03:00:00.000                 112   \n",
       "4        667     277996    678  2123-08-27 03:00:00.000  97.800003051757812   \n",
       "\n",
       "            valuenum  \n",
       "0               17.0  \n",
       "1  62.66669845581055  \n",
       "2               83.0  \n",
       "3              112.0  \n",
       "4  97.80000305175781  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%runSQL \n",
    "\n",
    "\n",
    "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum\n",
    "FROM patients p\n",
    "JOIN icustays i\n",
    "ON p.subject_id = i.subject_id\n",
    "JOIN chartevents c\n",
    "ON p.subject_id = c.subject_id\n",
    "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
    "LIMIT 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3bcbbb-5879-471b-8a56-f90ec3e9e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4995, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac88fa4-124e-4db5-bc68-e105db96d43e",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicSQL\n",
    "\n",
    "Same table, except also include whether that subject died in the hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e93ad0-519b-4ff0-9785-d5473b5fe122",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%runSQL \n",
    "\n",
    "\n",
    "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum, a.hospital_expire_flag\n",
    "FROM patients p\n",
    "JOIN icustays i\n",
    "ON p.subject_id = i.subject_id\n",
    "JOIN chartevents c\n",
    "ON p.subject_id = c.subject_id\n",
    "JOIN admissions a\n",
    "ON p.subject_id = a.subject_id\n",
    "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
    "LIMIT 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea67025-44ec-4031-a47d-5bf1312ba112",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicPython\n",
    "\n",
    "Can you take this table, and replace itemid with the relevant string-name for that item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9bcfe-6a08-4540-b117-7d69f97238b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##AI-generated-code\n",
    "\n",
    "\n",
    "# Create a dictionary where the keys are the itemid and the values are the corresponding string-names\n",
    "item_dict = {3348: 'Capillary refill rate', 8368: 'Diastolic blood pressure', 3420: 'Fraction inspired oxygen', \n",
    "             184: 'Glascow coma scale eye opening', 223901: 'Glascow coma scale motor response', 198: 'Glascow coma scale total', \n",
    "             223900: 'Glascow coma scale verbal response', 807: 'Glucose', 211: 'Heart Rate', 920: 'Height', \n",
    "             456: 'Mean blood pressure', 646: 'Oxygen saturation', 618: 'Respiratory rate', 51: 'Systolic blood pressure', \n",
    "             678: 'Temperature', 763: 'Weight', 780: 'pH'}\n",
    "\n",
    "# Replace the itemid in the dataframe with the corresponding string-names\n",
    "df['itemid'] = df['itemid'].replace(item_dict)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fecbf1-5e3c-4346-805e-e67c9a02d406",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicPython\n",
    "\n",
    "Great! What are the different itemids we have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e269a-e386-4b4b-acaa-0ae7bc68a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##AI-generated-code\n",
    "\n",
    "\n",
    "# Get the unique values in the 'itemid' column\n",
    "unique_itemids = df['itemid'].unique()\n",
    "\n",
    "print(unique_itemids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771ef97-f6da-4428-a06b-d77b904a3495",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicPython\n",
    "\n",
    "Great - lets take the df above, and group by icustay_id and hospital_expire_flag, and make new columns for each itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d33ad2-ee0f-404f-a7e9-3f9f5b3a2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##AI-generated-code\n",
    "\n",
    "\n",
    "# Pivot the dataframe to create new columns for each itemid\n",
    "df_pivot = df.pivot_table(index=['icustay_id', 'hospital_expire_flag'], columns='itemid', values='valuenum', aggfunc='mean')\n",
    "\n",
    "# Reset the index\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "print(df_pivot.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f13853-0eda-454f-886f-dd661bef6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce58e3-0710-40e2-8310-e5c405268a46",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicPython\n",
    "\n",
    "Now, I want to make a simple model that predicts whether the person dies in the hospital. Help me decide on a model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb6eca-e3a1-4234-a0d1-d277b904a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##AI-generated-code\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_pivot_imputed = imputer.fit_transform(df_pivot)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_pivot_imputed[:, :-1]  # Features\n",
    "y = df_pivot_imputed[:, -1]  # Target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed3d41-c68f-4a29-a8c1-13b473aed9b4",
   "metadata": {
    "ChapyterCell": {
     "cellType": "original"
    }
   },
   "outputs": [],
   "source": [
    "%%mimicPython\n",
    "\n",
    "ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31c443-e78e-476a-911b-7080f10dee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##AI-generated-code\n",
    "\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_pivot_imputed = pd.DataFrame(imputer.fit_transform(df_pivot), columns = df_pivot.columns)\n",
    "\n",
    "# Convert 'hospital_expire_flag' to int type\n",
    "df_pivot_imputed['hospital_expire_flag'] = df_pivot_imputed['hospital_expire_flag'].astype(int)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_pivot_imputed.drop('hospital_expire_flag', axis=1)  # Features\n",
    "y = df_pivot_imputed['hospital_expire_flag']  # Target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa223334-693c-4d39-b568-fbc31d4ad449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pivot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e649c920-5c7f-495a-8862-ef266a4d6664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 1609, 5963, 374, 2294, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encoding.encode(\"tiktoken is great!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5b9e5a0-df75-4fec-aa78-477624176e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_tokens_from_string(string, model_name):\n",
    "\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    \n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(\"tiktoken is great!\", \"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cde1e56b-e6b4-4a96-8ab3-a15aeb1bf6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"\"\"\n",
    "============================================================\n",
    "**Clinical Researcher:** # this notebook is based on the following study\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
    "\n",
    "**AI Research Assistant:** None\n",
    "============================================================\n",
    "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
    "\n",
    "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
    "\n",
    "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
    "============================================================\n",
    "**Clinical Researcher:** %%runSQL  --- \n",
    "SELECT *\n",
    "FROM patients p\n",
    "JOIN chartevents c\n",
    "ON p.subject_id = c.subject_id\n",
    "\n",
    "**AI Research Assistant:** None\n",
    "============================================================\n",
    "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
    "\n",
    "**AI Research Assistant:** None\n",
    "============================================================\n",
    "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
    "2. Diastolic blood pressure\n",
    "3. Fraction inspired oxygen\n",
    "4. Glascow coma scale eye opening\n",
    "5. Glascow coma scale motor response\n",
    "6. Glascow coma scale total\n",
    "7. Glascow coma scale verbal response\n",
    "8. Glucose\n",
    "9. Heart Rate\n",
    "10. Height\n",
    "11. Mean blood pressure\n",
    "12. Oxygen saturation\n",
    "13. Respiratory rate\n",
    "14. Systolic blood pressure\n",
    "15. Temperature\n",
    "16. Weight\n",
    "17. pH\n",
    "\n",
    "**AI Research Assistant:** None\n",
    "============================================================\n",
    "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal\n",
    "\n",
    "**AI Research Assistant:**\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0062315-9bb7-46bd-97d7-1c96ef76f036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(my_string, \"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22b50ebb-b362-4ed9-9086-e77120bdce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleSpec(name='tiktoken', loader=<_frozen_importlib_external.SourceFileLoader object at 0x29319a1a0>, origin='/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken/__init__.py', submodule_search_locations=['/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.__spec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12bdf246-c478-4ece-aa1d-5d94d8e06fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:** ============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** # %%mimicRevealChatHistory --- # Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 400 tokens!\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum\n",
      "FROM patients p\n",
      "JOIN icustays i\n",
      "ON p.subject_id = i.subject_id\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
      "LIMIT 5000\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "  subject_id icustay_id itemid                charttime               value  \\\n",
      "0        667     277996    618  2123-08-27 04:00:00.000                  17   \n",
      "1        667     277996    456  2123-08-27 04:00:00.000  62.666698455810547   \n",
      "2        667     277996    211  2123-08-27 04:00:00.000                  83   \n",
      "3        667     277996    807  2123-08-27 03:00:00.000                 112   \n",
      "4        667     277996    678  2123-08-27 03:00:00.000  97.800003051757812   \n",
      "\n",
      "            valuenum  \n",
      "0               17.0  \n",
      "1  62.66669845581055  \n",
      "2               83.0  \n",
      "3              112.0  \n",
      "4  97.80000305175781  \n",
      "============================================================\n",
      "**Clinical Researcher:** print(df.shape)\n",
      "\n",
      "**AI Research Assistant:** (4995, 6)\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Same table, except also include whether that subject died in the hospital\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum, a.hospital_expire_flag\n",
      "FROM patients p\n",
      "JOIN icustays i\n",
      "ON p.subject_id = i.subject_id\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "JOIN admissions a\n",
      "ON p.subject_id = a.subject_id\n",
      "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
      "LIMIT 50000\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Can you take this table, and replace itemid with the relevant string-name for that item?\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Create a dictionary where the keys are the itemid and the values are the corresponding string-names\n",
      "item_dict = {3348: 'Capillary refill rate', 8368: 'Diastolic blood pressure', 3420: 'Fraction inspired oxygen', \n",
      "             184: 'Glascow coma scale eye opening', 223901: 'Glascow coma scale motor response', 198: 'Glascow coma scale total', \n",
      "             223900: 'Glascow coma scale verbal response', 807: 'Glucose', 211: 'Heart Rate', 920: 'Height', \n",
      "             456: 'Mean blood pressure', 646: 'Oxygen saturation', 618: 'Respiratory rate', 51: 'Systolic blood pressure', \n",
      "             678: 'Temperature', 763: 'Weight', 780: 'pH'} --- # Replace the itemid in the dataframe with the corresponding string-names\n",
      "df['itemid'] = df['itemid'].replace(item_dict) --- print(df.head())\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Great! What are the different itemids we have now?\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Get the unique values in the 'itemid' column\n",
      "unique_itemids = df['itemid'].unique() --- print(unique_itemids)\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Great - lets take the df above, and group by icustay_id and hospital_expire_flag, and make new columns for each itemid\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Pivot the dataframe to create new columns for each itemid\n",
      "df_pivot = df.pivot_table(index=['icustay_id', 'hospital_expire_flag'], columns='itemid', values='valuenum', aggfunc='mean') --- # Reset the index\n",
      "df_pivot.reset_index(inplace=True) --- print(df_pivot.head())\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** df_pivot\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Now, I want to make a simple model that predicts whether the person dies in the hospital. Help me decide on a model and train it.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.impute import SimpleImputer --- # Handle missing values\n",
      "imputer = SimpleImputer(strategy='mean')\n",
      "df_pivot_imputed = imputer.fit_transform(df_pivot) --- # Split the data into features and target\n",
      "X = df_pivot_imputed[:, :-1]  # Features\n",
      "y = df_pivot_imputed[:, -1]  # Target --- # Standardize the features\n",
      "scaler = StandardScaler()\n",
      "X = scaler.fit_transform(X) --- # Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) --- # Create a Logistic Regression model\n",
      "model = LogisticRegression() --- # Train the model\n",
      "model.fit(X_train, y_train) --- # Make predictions on the test set\n",
      "y_pred = model.predict(X_test) --- # Print the accuracy of the model\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred)) --- # Print the confusion matrix\n",
      "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred)) --- # Print the classification report\n",
      "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Handle missing values\n",
      "imputer = SimpleImputer(strategy='mean')\n",
      "df_pivot_imputed = pd.DataFrame(imputer.fit_transform(df_pivot), columns = df_pivot.columns) --- # Convert 'hospital_expire_flag' to int type\n",
      "df_pivot_imputed['hospital_expire_flag'] = df_pivot_imputed['hospital_expire_flag'].astype(int) --- # Split the data into features and target\n",
      "X = df_pivot_imputed.drop('hospital_expire_flag', axis=1)  # Features\n",
      "y = df_pivot_imputed['hospital_expire_flag']  # Target --- # Standardize the features\n",
      "scaler = StandardScaler()\n",
      "X = scaler.fit_transform(X) --- # Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) --- # Create a Logistic Regression model\n",
      "model = LogisticRegression() --- # Train the model\n",
      "model.fit(X_train, y_train) --- # Make predictions on the test set\n",
      "y_pred = model.predict(X_test) --- # Print the accuracy of the model\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred)) --- # Print the confusion matrix\n",
      "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred)) --- # Print the classification report\n",
      "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** print(df_pivot.shape)\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** import tiktoken --- encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
      "encoding.encode(\"tiktoken is great!\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "[83, 1609, 5963, 374, 2294, 0]\n",
      "============================================================\n",
      "**Clinical Researcher:** def num_tokens_from_string(string, model_name): ---     \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
      "    \n",
      "    encoding = tiktoken.encoding_for_model(model_name)\n",
      "    num_tokens = len(encoding.encode(string))\n",
      "    return num_tokens --- num_tokens_from_string(\"tiktoken is great!\", \"gpt-3.5-turbo\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "6\n",
      "============================================================\n",
      "**Clinical Researcher:** my_string = \"\"\"\n",
      "============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/ --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III? --- **AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this: --- This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them. --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal --- **AI Research Assistant:**\n",
      "\"\"\"\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** num_tokens_from_string(my_string, \"gpt-3.5-turbo\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "396\n",
      "============================================================\n",
      "**Clinical Researcher:** tiktoken.__spec__\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "ModuleSpec(name='tiktoken', loader=<_frozen_importlib_external.SourceFileLoader object at 0x29319a1a0>, origin='/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken/__init__.py', submodule_search_locations=['/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken'])\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 3395 tokens!\n"
     ]
    }
   ],
   "source": [
    "%%mimicRevealChatHistory\n",
    "\n",
    "Reveal all of these tokens!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d47fc63-7c22-4b48-8b58-e50c279cb971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:** ============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** # %%mimicRevealChatHistory --- # Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 400 tokens!\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum\n",
      "FROM patients p\n",
      "JOIN icustays i\n",
      "ON p.subject_id = i.subject_id\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
      "LIMIT 5000\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "  subject_id icustay_id itemid                charttime               value  \\\n",
      "0        667     277996    618  2123-08-27 04:00:00.000                  17   \n",
      "1        667     277996    456  2123-08-27 04:00:00.000  62.666698455810547   \n",
      "2        667     277996    211  2123-08-27 04:00:00.000                  83   \n",
      "3        667     277996    807  2123-08-27 03:00:00.000                 112   \n",
      "4        667     277996    678  2123-08-27 03:00:00.000  97.800003051757812   \n",
      "\n",
      "            valuenum  \n",
      "0               17.0  \n",
      "1  62.66669845581055  \n",
      "2               83.0  \n",
      "3              112.0  \n",
      "4  97.80000305175781  \n",
      "============================================================\n",
      "**Clinical Researcher:** print(df.shape)\n",
      "\n",
      "**AI Research Assistant:** (4995, 6)\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Same table, except also include whether that subject died in the hospital\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum, a.hospital_expire_flag\n",
      "FROM patients p\n",
      "JOIN icustays i\n",
      "ON p.subject_id = i.subject_id\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "JOIN admissions a\n",
      "ON p.subject_id = a.subject_id\n",
      "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
      "LIMIT 50000\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Can you take this table, and replace itemid with the relevant string-name for that item?\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Create a dictionary where the keys are the itemid and the values are the corresponding string-names\n",
      "item_dict = {3348: 'Capillary refill rate', 8368: 'Diastolic blood pressure', 3420: 'Fraction inspired oxygen', \n",
      "             184: 'Glascow coma scale eye opening', 223901: 'Glascow coma scale motor response', 198: 'Glascow coma scale total', \n",
      "             223900: 'Glascow coma scale verbal response', 807: 'Glucose', 211: 'Heart Rate', 920: 'Height', \n",
      "             456: 'Mean blood pressure', 646: 'Oxygen saturation', 618: 'Respiratory rate', 51: 'Systolic blood pressure', \n",
      "             678: 'Temperature', 763: 'Weight', 780: 'pH'} --- # Replace the itemid in the dataframe with the corresponding string-names\n",
      "df['itemid'] = df['itemid'].replace(item_dict) --- print(df.head())\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Great! What are the different itemids we have now?\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Get the unique values in the 'itemid' column\n",
      "unique_itemids = df['itemid'].unique() --- print(unique_itemids)\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Great - lets take the df above, and group by icustay_id and hospital_expire_flag, and make new columns for each itemid\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Pivot the dataframe to create new columns for each itemid\n",
      "df_pivot = df.pivot_table(index=['icustay_id', 'hospital_expire_flag'], columns='itemid', values='valuenum', aggfunc='mean') --- # Reset the index\n",
      "df_pivot.reset_index(inplace=True) --- print(df_pivot.head())\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** df_pivot\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Now, I want to make a simple model that predicts whether the person dies in the hospital. Help me decide on a model and train it.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.impute import SimpleImputer --- # Handle missing values\n",
      "imputer = SimpleImputer(strategy='mean')\n",
      "df_pivot_imputed = imputer.fit_transform(df_pivot) --- # Split the data into features and target\n",
      "X = df_pivot_imputed[:, :-1]  # Features\n",
      "y = df_pivot_imputed[:, -1]  # Target --- # Standardize the features\n",
      "scaler = StandardScaler()\n",
      "X = scaler.fit_transform(X) --- # Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) --- # Create a Logistic Regression model\n",
      "model = LogisticRegression() --- # Train the model\n",
      "model.fit(X_train, y_train) --- # Make predictions on the test set\n",
      "y_pred = model.predict(X_test) --- # Print the accuracy of the model\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred)) --- # Print the confusion matrix\n",
      "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred)) --- # Print the classification report\n",
      "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Handle missing values\n",
      "imputer = SimpleImputer(strategy='mean')\n",
      "df_pivot_imputed = pd.DataFrame(imputer.fit_transform(df_pivot), columns = df_pivot.columns) --- # Convert 'hospital_expire_flag' to int type\n",
      "df_pivot_imputed['hospital_expire_flag'] = df_pivot_imputed['hospital_expire_flag'].astype(int) --- # Split the data into features and target\n",
      "X = df_pivot_imputed.drop('hospital_expire_flag', axis=1)  # Features\n",
      "y = df_pivot_imputed['hospital_expire_flag']  # Target --- # Standardize the features\n",
      "scaler = StandardScaler()\n",
      "X = scaler.fit_transform(X) --- # Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) --- # Create a Logistic Regression model\n",
      "model = LogisticRegression() --- # Train the model\n",
      "model.fit(X_train, y_train) --- # Make predictions on the test set\n",
      "y_pred = model.predict(X_test) --- # Print the accuracy of the model\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred)) --- # Print the confusion matrix\n",
      "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred)) --- # Print the classification report\n",
      "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** print(df_pivot.shape)\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** import tiktoken --- encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
      "encoding.encode(\"tiktoken is great!\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "[83, 1609, 5963, 374, 2294, 0]\n",
      "============================================================\n",
      "**Clinical Researcher:** def num_tokens_from_string(string, model_name): ---     \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
      "    \n",
      "    encoding = tiktoken.encoding_for_model(model_name)\n",
      "    num_tokens = len(encoding.encode(string))\n",
      "    return num_tokens --- num_tokens_from_string(\"tiktoken is great!\", \"gpt-3.5-turbo\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "6\n",
      "============================================================\n",
      "**Clinical Researcher:** my_string = \"\"\"\n",
      "============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/ --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III? --- **AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this: --- This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them. --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal --- **AI Research Assistant:**\n",
      "\"\"\"\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** num_tokens_from_string(my_string, \"gpt-3.5-turbo\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "396\n",
      "============================================================\n",
      "**Clinical Researcher:** tiktoken.__spec__\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "ModuleSpec(name='tiktoken', loader=<_frozen_importlib_external.SourceFileLoader object at 0x29319a1a0>, origin='/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken/__init__.py', submodule_search_locations=['/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken'])\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!!\n",
      "\n",
      "**AI Research Assistant:** ============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:** ============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III?\n",
      "\n",
      "**AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this:\n",
      "\n",
      "This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** # %%mimicRevealChatHistory --- # Reveal all of these tokens!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 400 tokens!\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum\n",
      "FROM patients p\n",
      "JOIN icustays i\n",
      "ON p.subject_id = i.subject_id\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
      "LIMIT 5000\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "  subject_id icustay_id itemid                charttime               value  \\\n",
      "0        667     277996    618  2123-08-27 04:00:00.000                  17   \n",
      "1        667     277996    456  2123-08-27 04:00:00.000  62.666698455810547   \n",
      "2        667     277996    211  2123-08-27 04:00:00.000                  83   \n",
      "3        667     277996    807  2123-08-27 03:00:00.000                 112   \n",
      "4        667     277996    678  2123-08-27 03:00:00.000  97.800003051757812   \n",
      "\n",
      "            valuenum  \n",
      "0               17.0  \n",
      "1  62.66669845581055  \n",
      "2               83.0  \n",
      "3              112.0  \n",
      "4  97.80000305175781  \n",
      "============================================================\n",
      "**Clinical Researcher:** print(df.shape)\n",
      "\n",
      "**AI Research Assistant:** (4995, 6)\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Same table, except also include whether that subject died in the hospital\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT p.subject_id, i.icustay_id, c.itemid, c.charttime, c.value, c.valuenum, a.hospital_expire_flag\n",
      "FROM patients p\n",
      "JOIN icustays i\n",
      "ON p.subject_id = i.subject_id\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id\n",
      "JOIN admissions a\n",
      "ON p.subject_id = a.subject_id\n",
      "WHERE c.itemid IN (3348, 8368, 3420, 184, 223901, 198, 223900, 807, 211, 920, 456, 646, 618, 51, 678, 763, 780)\n",
      "LIMIT 50000\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Can you take this table, and replace itemid with the relevant string-name for that item?\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Create a dictionary where the keys are the itemid and the values are the corresponding string-names\n",
      "item_dict = {3348: 'Capillary refill rate', 8368: 'Diastolic blood pressure', 3420: 'Fraction inspired oxygen', \n",
      "             184: 'Glascow coma scale eye opening', 223901: 'Glascow coma scale motor response', 198: 'Glascow coma scale total', \n",
      "             223900: 'Glascow coma scale verbal response', 807: 'Glucose', 211: 'Heart Rate', 920: 'Height', \n",
      "             456: 'Mean blood pressure', 646: 'Oxygen saturation', 618: 'Respiratory rate', 51: 'Systolic blood pressure', \n",
      "             678: 'Temperature', 763: 'Weight', 780: 'pH'} --- # Replace the itemid in the dataframe with the corresponding string-names\n",
      "df['itemid'] = df['itemid'].replace(item_dict) --- print(df.head())\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Great! What are the different itemids we have now?\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Get the unique values in the 'itemid' column\n",
      "unique_itemids = df['itemid'].unique() --- print(unique_itemids)\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Great - lets take the df above, and group by icustay_id and hospital_expire_flag, and make new columns for each itemid\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Pivot the dataframe to create new columns for each itemid\n",
      "df_pivot = df.pivot_table(index=['icustay_id', 'hospital_expire_flag'], columns='itemid', values='valuenum', aggfunc='mean') --- # Reset the index\n",
      "df_pivot.reset_index(inplace=True) --- print(df_pivot.head())\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** df_pivot\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- Now, I want to make a simple model that predicts whether the person dies in the hospital. Help me decide on a model and train it.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.impute import SimpleImputer --- # Handle missing values\n",
      "imputer = SimpleImputer(strategy='mean')\n",
      "df_pivot_imputed = imputer.fit_transform(df_pivot) --- # Split the data into features and target\n",
      "X = df_pivot_imputed[:, :-1]  # Features\n",
      "y = df_pivot_imputed[:, -1]  # Target --- # Standardize the features\n",
      "scaler = StandardScaler()\n",
      "X = scaler.fit_transform(X) --- # Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) --- # Create a Logistic Regression model\n",
      "model = LogisticRegression() --- # Train the model\n",
      "model.fit(X_train, y_train) --- # Make predictions on the test set\n",
      "y_pred = model.predict(X_test) --- # Print the accuracy of the model\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred)) --- # Print the confusion matrix\n",
      "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred)) --- # Print the classification report\n",
      "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicPython --- ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** ##AI-generated-code --- \n",
      "# Handle missing values\n",
      "imputer = SimpleImputer(strategy='mean')\n",
      "df_pivot_imputed = pd.DataFrame(imputer.fit_transform(df_pivot), columns = df_pivot.columns) --- # Convert 'hospital_expire_flag' to int type\n",
      "df_pivot_imputed['hospital_expire_flag'] = df_pivot_imputed['hospital_expire_flag'].astype(int) --- # Split the data into features and target\n",
      "X = df_pivot_imputed.drop('hospital_expire_flag', axis=1)  # Features\n",
      "y = df_pivot_imputed['hospital_expire_flag']  # Target --- # Standardize the features\n",
      "scaler = StandardScaler()\n",
      "X = scaler.fit_transform(X) --- # Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) --- # Create a Logistic Regression model\n",
      "model = LogisticRegression() --- # Train the model\n",
      "model.fit(X_train, y_train) --- # Make predictions on the test set\n",
      "y_pred = model.predict(X_test) --- # Print the accuracy of the model\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred)) --- # Print the confusion matrix\n",
      "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred)) --- # Print the classification report\n",
      "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** print(df_pivot.shape)\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** import tiktoken --- encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
      "encoding.encode(\"tiktoken is great!\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "[83, 1609, 5963, 374, 2294, 0]\n",
      "============================================================\n",
      "**Clinical Researcher:** def num_tokens_from_string(string, model_name): ---     \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
      "    \n",
      "    encoding = tiktoken.encoding_for_model(model_name)\n",
      "    num_tokens = len(encoding.encode(string))\n",
      "    return num_tokens --- num_tokens_from_string(\"tiktoken is great!\", \"gpt-3.5-turbo\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "6\n",
      "============================================================\n",
      "**Clinical Researcher:** my_string = \"\"\"\n",
      "============================================================\n",
      "**Clinical Researcher:** # this notebook is based on the following study\n",
      "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687414/ --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- How can I join patients and chartevents tables in MIMIC-III? --- **AI Research Assistant:** You can join the `patients` and `chartevents` tables on the `subject_id` column, which is common to both tables. Here is a basic SQL query to do this: --- This will return all columns from both tables where the `subject_id` matches in both tables. You can replace the `*` with specific column names if you only want to return certain columns.\n",
      "============================================================\n",
      "**Clinical Researcher:** %%runSQL  --- \n",
      "SELECT *\n",
      "FROM patients p\n",
      "JOIN chartevents c\n",
      "ON p.subject_id = c.subject_id --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- Great, lets create a table that joins them. --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicSQL --- same thing, but include icustay, as well as chart events for --- 1. Capillary refill rate\n",
      "2. Diastolic blood pressure\n",
      "3. Fraction inspired oxygen\n",
      "4. Glascow coma scale eye opening\n",
      "5. Glascow coma scale motor response\n",
      "6. Glascow coma scale total\n",
      "7. Glascow coma scale verbal response\n",
      "8. Glucose\n",
      "9. Heart Rate\n",
      "10. Height\n",
      "11. Mean blood pressure\n",
      "12. Oxygen saturation\n",
      "13. Respiratory rate\n",
      "14. Systolic blood pressure\n",
      "15. Temperature\n",
      "16. Weight\n",
      "17. pH --- **AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal --- **AI Research Assistant:**\n",
      "\"\"\"\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** num_tokens_from_string(my_string, \"gpt-3.5-turbo\")\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "396\n",
      "============================================================\n",
      "**Clinical Researcher:** tiktoken.__spec__\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "ModuleSpec(name='tiktoken', loader=<_frozen_importlib_external.SourceFileLoader object at 0x29319a1a0>, origin='/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken/__init__.py', submodule_search_locations=['/Users/emmettgoodman/miniconda3/lib/python3.10/site-packages/tiktoken'])\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 3395 tokens!\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!!\n",
      "\n",
      "**AI Research Assistant:** None\n",
      "============================================================\n",
      "**Clinical Researcher:** %%mimicRevealChatHistory --- Reveal all of these tokens!!\n",
      "\n",
      "**AI Research Assistant:**\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Current history is 6860 tokens!\n"
     ]
    }
   ],
   "source": [
    "%%mimicRevealChatHistory\n",
    "\n",
    "Reveal all of these tokens!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d1fb1f5b-8d0e-4fa7-bc0b-eaef8055d975",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 13964 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmimicSQL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSQL query to retrieve all data from patients\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/startup/mocha/code/sept25/chapyterMed/chapyter/magic.py:341\u001b[0m, in \u001b[0;36mChapyter.mimicSQL\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    321\u001b[0m overall_sys_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124m             You are a Medical AI Research Assistant, helping a Clinical Researcher do analyses of the MIMIC-III dataset on AWS Athena.\u001b[39m\n\u001b[1;32m    323\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124m             Return all SQL queries between two sets of triple ticks.                   \u001b[39m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124m             \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    339\u001b[0m context \u001b[38;5;241m=\u001b[39m get_notebook_ordered_history(current_message, os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOTEBOOK_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 341\u001b[0m program_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverall_sys_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_responses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m#regex to get rid of SQL in the response\u001b[39;00m\n\u001b[1;32m    344\u001b[0m program_out_noSQL_list \u001b[38;5;241m=\u001b[39m program_out\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/startup/mocha/code/sept25/chapyterMed/chapyter/magic.py:268\u001b[0m, in \u001b[0;36mChapyter.execute_chat\u001b[0;34m(self, message, args, shell, sys_prompt, llm_responses, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m program \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_program(args, chatonly\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatonly\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    266\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(args, program)\n\u001b[0;32m--> 268\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_responses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_responses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/startup/mocha/code/sept25/chapyterMed/chapyter/programs.py:40\u001b[0m, in \u001b[0;36mChapyterAgentProgram.execute\u001b[0;34m(self, message, llm, shell, sys_prompt, llm_responses, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: \u001b[38;5;28mstr\u001b[39m, llm: \u001b[38;5;28mstr\u001b[39m, shell: InteractiveShell, sys_prompt: \u001b[38;5;28mstr\u001b[39m, llm_responses: \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     llm_response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm_response\n",
      "File \u001b[0;32m~/Documents/startup/mocha/code/sept25/chapyterMed/chapyter/athena_utils.py:96\u001b[0m, in \u001b[0;36mquery_llm\u001b[0;34m(llm_prompt, sys_prompt)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_llm\u001b[39m(llm_prompt, sys_prompt):\n\u001b[0;32m---> 96\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msys_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 13964 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "%%mimicSQL \n",
    "\n",
    "SQL query to retrieve all data from patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d5d32-0723-4af0-885e-545fee283d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
