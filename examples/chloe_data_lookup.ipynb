{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f303ff26-5b2c-4261-96ab-8096dd0b544b",
   "metadata": {},
   "source": [
    "\n",
    "# Data dictionary usage\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f918b1d-a5c7-443f-a9be-4792f5df2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200575f-8f27-4a13-9d76-c254ca0c4c5e",
   "metadata": {},
   "source": [
    "First, let's try to use the MIMIC data dictionary to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f89b34-9a1f-4f58-91d9-dc3a06eddd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# The vectorstore we'll be using\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# The LangChain component we'll use to get the documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# The easy document loader for text\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd055ed7-740d-452b-b9f7-05b4da7dcdd5",
   "metadata": {},
   "source": [
    "Let's first load the MIMIC data dictionary, just copied and pasted from the website into one large doc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be286547-cf2e-49b4-a4c7-5e7714dff6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 75423 characters in that document\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('/Users/chloeoconnell/Documents/Data/Mimic_dictionary.txt')\n",
    "doc = loader.load()\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c29c4fb-c4fb-478e-9710-fb1302d06274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 35 documents that have an average of 2,341 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)\n",
    "\n",
    "# Get the total number of characters so we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e59910b-2d03-430c-b20f-e7a2bb0030df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8dac9d-7a26-4827-a3b8-7d04e09252e3",
   "metadata": {},
   "source": [
    "Create the retrieval engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac00840-2b34-4fcb-8b17-4a55bb47927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4729cba0-046b-40e7-8762-6a9a7db378d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The DESCRIPTION column in the CPTEVENTS table provides information about the meaning of CPT codes related to ventilation.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Where can information be found about ventilator settings?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15377b2-a6e5-4132-811e-2ff01d6811cc",
   "metadata": {},
   "source": [
    "# Getting info from the database itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920a2b9-1e48-45be-b4a5-3bd046bbc4c2",
   "metadata": {},
   "source": [
    "First, we need to make a sql database from the dictionary tables in MIMIC (D_***.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c94ecbc5-cc1a-415d-bc45-f0d2c22a0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a5b56d-adb5-4a6a-8ca8-75da82c675dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = sqlite3.connect('mimic_dictionaries.db')\n",
    "folder_path = '/Users/chloeoconnell/Documents/Data/MIMIC'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    table_name = os.path.splitext(csv_file)[0]  # Use the CSV filename as the table name\n",
    "    df = pd.read_csv(os.path.join(folder_path, csv_file))\n",
    "    df.to_sql(table_name, db_connection, if_exists='replace', index=False)\n",
    "\n",
    "db_connection.commit()\n",
    "db_connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2f29da-10db-4978-a217-09631b5af250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeoconnell/opt/anaconda3/envs/lc_env/lib/python3.8/site-packages/langchain_experimental/sql/base.py:75: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlite_db_path = 'mimic_dictionaries.db'  # Replace with the path to your SQLite database\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\n",
    "\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4693e600-3df7-40ce-a1b7-1d117ab63424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "What are some ICD-9 codes that can be used to identify renal replacement therapy?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT icd9_code, short_title, long_title FROM D_ICD_DIAGNOSES WHERE long_title LIKE '%renal replacement therapy%';\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3micd9_code: 39.95, short_title: Renal replac ther, long_title: Renal replacement therapy.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'icd9_code: 39.95, short_title: Renal replac ther, long_title: Renal replacement therapy.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.run(\"What are some ICD-9 codes that can be used to identify renal replacement therapy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94680b80-79a9-4369-9f7f-5962570865aa",
   "metadata": {},
   "source": [
    "# Creating an agent\n",
    "We want to incorporate both data dictionary text and sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab64a993-7c35-4b94-935a-ec7e201903f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "\n",
    "#csv_path = '/Users/chloeoconnell/Documents/Data/MIMIC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2daac8-d0a9-44da-b2b0-ff8f705f8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('/Users/chloeoconnell/Documents/Data/Mimic_dictionary.txt')\n",
    "txt_doc = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(txt_doc)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(docs, embeddings, collection_name=\"mimic_descriptions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05582f91-83a9-4608-9907-7bb868d89efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_text = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "017e8e2f-90d7-47a8-92e8-8f06243effc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://github.com/MIT-LCP/mimic-code\")\n",
    "docs = loader.load()\n",
    "mimic_code = text_splitter.split_documents(docs)\n",
    "mimic_code_db = Chroma.from_documents(mimic_code, embeddings, collection_name=\"code\")\n",
    "code = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=mimic_code_db.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a57a9ccf-ac40-44ce-b127-4f42bab317c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f424dce-56a0-4976-b540-d6aee384f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"MIMIC data description\",\n",
    "        func=mimic_text.run,\n",
    "        description=\"useful for when you need to answer questions about what is contained in each csv of MIMIC.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"MIMIC code repo\",\n",
    "        func=code.run,\n",
    "        description=\"useful for when you need sample code that manipulates the data in MIMIC and creates additional variables.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a918c14-9a95-40a3-ada4-5f677d2c944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a way to calculate urine output from the data.\n",
      "Action: MIMIC code repo\n",
      "Action Input: urine output\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m The MIMIC Code Repository does not contain any code related to urine output.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find a way to calculate urine output from the data.\n",
      "Action: MIMIC data description\n",
      "Action Input: urine output\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Urine output is not listed in the inputevents_cv or inputevents_mv tables. It is listed in the labevents table, with the ITEMID of 40055.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Urine output can be determined from the MIMIC-III database by looking at the labevents table and using the ITEMID of 40055.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Urine output can be determined from the MIMIC-III database by looking at the labevents table and using the ITEMID of 40055.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the agent. \n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\n",
    "    \"Is there a way to determine urine output from the MIMIC-III database with code?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee8f75-95a8-4308-92ff-2d9964998e94",
   "metadata": {},
   "source": [
    "It partially works, but the MIMIC repo isn't being fully used. Let's upload it another way: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9d86b-14b2-432a-a04e-efa6933f4f09",
   "metadata": {},
   "source": [
    "# Embedding github repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45d9b319-6746-4310-9f55-160865899a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "root_dir = '/Users/chloeoconnell/Documents/Data/mimic-code/mimic-iii/concepts'\n",
    "docs = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load up the file as a doc and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4551c992-9834-4c1e-b2f7-8de475d27953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 237 documents\n",
      "\n",
      "------ Start Document ------\n",
      "-- This query extracts:\n",
      "--    i) a patient's first code status\n",
      "--    ii) a patient's last code status\n",
      "--    iii) the time of the first entry of DNR or CMO\n",
      "\n",
      "with t1 as\n",
      "(\n",
      "  select icustay_id, charttime, value\n",
      "  -- use row number to identify first and last code status\n",
      "  , ROW_NUMBER() over (PARTITION B\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(docs)} documents\\n\")\n",
    "print (\"------ Start Document ------\")\n",
    "print (docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92b436e3-a04e-4815-b877-5b9c5ed0dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too large to use this method of embeddings\n",
    "docsearch = FAISS.from_documents(docs, embeddings)\n",
    "# Get our retriever ready\n",
    "github_qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b82cbe06-6ae7-4bcc-ad72-e49042c51ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2669, which is longer than the specified 2000\n",
      "Created a chunk of size 2868, which is longer than the specified 2000\n",
      "Created a chunk of size 3610, which is longer than the specified 2000\n",
      "Created a chunk of size 2217, which is longer than the specified 2000\n",
      "Created a chunk of size 2143, which is longer than the specified 2000\n",
      "Created a chunk of size 2381, which is longer than the specified 2000\n",
      "Created a chunk of size 2929, which is longer than the specified 2000\n",
      "Created a chunk of size 2997, which is longer than the specified 2000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=10)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20a710fe-83fa-414b-b097-51d06dc65e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 393\n"
     ]
    }
   ],
   "source": [
    "num_texts = len(texts)\n",
    "print(f\"Number of texts: {num_texts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "282db32a-2d76-44eb-868f-b2aa03941578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class RateLimitedEmbeddings:\n",
    "    def __init__(self, max_tokens_per_minute=1000000):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.max_tokens = max_tokens_per_minute\n",
    "        self.tokens_processed = 0\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def _count_tokens(self, texts):\n",
    "        return sum(len(text.split()) for text in texts)  # Simple whitespace-based tokenization\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        tokens_in_batch = self._count_tokens(texts)\n",
    "\n",
    "        # If the tokens in this batch exceed the limit, wait\n",
    "        while self.tokens_processed + tokens_in_batch > self.max_tokens:\n",
    "            elapsed_time = time.time() - self.start_time\n",
    "            time_to_wait = 60 - elapsed_time\n",
    "            if time_to_wait > 0:\n",
    "                time.sleep(time_to_wait)\n",
    "            self.tokens_processed = 0\n",
    "            self.start_time = time.time()\n",
    "\n",
    "        embeddings = self.embeddings.embed_documents(texts)\n",
    "        self.tokens_processed += tokens_in_batch\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        tokens_in_query = len(query.split())  # Simple whitespace-based tokenization\n",
    "\n",
    "        # If the tokens in the query exceed the limit, wait\n",
    "        while self.tokens_processed + tokens_in_query > self.max_tokens:\n",
    "            elapsed_time = time.time() - self.start_time\n",
    "            time_to_wait = 60 - elapsed_time\n",
    "            if time_to_wait > 0:\n",
    "                time.sleep(time_to_wait)\n",
    "            self.tokens_processed = 0\n",
    "            self.start_time = time.time()\n",
    "\n",
    "        embedding = self.embeddings.embed_query(query)  # Assuming the original OpenAIEmbeddings has this method\n",
    "        self.tokens_processed += tokens_in_query\n",
    "\n",
    "        return embedding\n",
    "\n",
    "# Use the rate-limited embeddings class\n",
    "rate_limited_embeddings = RateLimitedEmbeddings()\n",
    "github_search = Chroma.from_documents(texts, rate_limited_embeddings, collection_name=\"mimic_code_chroma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a148bc-8633-44cc-b38b-4e4d0b7b34eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22a18d48-a82f-45f1-aad7-cbcbe1baad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "github_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=github_search.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08f6b164-07b9-41a6-993e-e0167991f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"MIMIC data description\",\n",
    "        func=mimic_text.run,\n",
    "        description=\"useful for when you need to answer questions about what is contained in each csv of MIMIC.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"MIMIC code repo\",\n",
    "        func=github_qa.run,\n",
    "        description=\"useful for when you need sample code that manipulates the data in MIMIC and creates additional variables.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51252163-a8ca-40b4-a23a-9c3cbf62c169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a way to calculate the SOFA score from the MIMIC-III database.\n",
      "Action: MIMIC code repo\n",
      "Action Input: SOFA score\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m The SOFA score was first developed by a consensus meeting of the ESICM in October 1994. It is an objective measure of the severity of organ dysfunction in a patient and is evaluated for 6 organ systems: pulmonary, renal, hepatic, cardiovascular, haematologic and neurologic. It is not meant as a direct predictor of mortality but rather a measure of morbidity.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the code that calculates the SOFA score from the MIMIC-III database.\n",
      "Action: MIMIC code repo\n",
      "Action Input: SOFA score calculation\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m The SOFA score is calculated by evaluating 6 organ systems: pulmonary, renal, hepatic, cardiovascular, haematologic and neurologic. The organ-specific morbidity scores are highlighted as a useful compliment to the overall score.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Yes, there is a way to determine SOFA score from the MIMIC-III database with sample code. The code to calculate the SOFA score can be found in the MIMIC code repo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, there is a way to determine SOFA score from the MIMIC-III database with sample code. The code to calculate the SOFA score can be found in the MIMIC code repo.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the agent. \n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\n",
    "    \"Is there a way to determine SOFA score from the MIMIC-III database with sample code? If so, can you give me that sql code? Do not simply return the definition of the SOFA score - I want the code that calculates the score.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aac2f0-8b5e-4b6d-97bd-d74f258e394b",
   "metadata": {},
   "source": [
    "A bit better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "412c4406-2e73-48bc-be86-7367e28255b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to know which ICD-9 codes are used in the vanWalRaven method.\n",
      "Action: MIMIC data description\n",
      "Action Input: vanWalRaven method\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find a code repo that can help me calculate the elixhauser comorbidity score.\n",
      "Action: MIMIC code repo\n",
      "Action Input: elixhauser comorbidity score\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m The Elixhauser comorbidity score is calculated using two methods: van Walraven and SID29. The van Walraven score is calculated by multiplying the presence of each comorbidity by a certain number and adding them together. The SID29 score is calculated in a similar way.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know which ICD-9 codes to use to calculate the elixhauser comorbidity score using the vanWalRaven method.\n",
      "Final Answer: The ICD-9 codes used to calculate the elixhauser comorbidity score using the vanWalRaven method are: 001-139, 140-239, 280-289, 290-319, 320-389, 390-459, 460-519, 520-579, 580-629, 630-679, 680-709, 710-739, 740-759, 760-779, 780-799, 800-999.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The ICD-9 codes used to calculate the elixhauser comorbidity score using the vanWalRaven method are: 001-139, 140-239, 280-289, 290-319, 320-389, 390-459, 460-519, 520-579, 580-629, 630-679, 680-709, 710-739, 740-759, 760-779, 780-799, 800-999.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"If I wanted to calculate the elixhauser comorbidity score using the vanWalRaven method, which ICD-9 codes could I use to do this?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22845d75-64a9-4a48-91f2-7edc50fcced0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a way to identify which patients got renal replacement therapy.\n",
      "Action: MIMIC data description\n",
      "Action Input: renal replacement therapy\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find a way to identify which patients got renal replacement therapy from the data.\n",
      "Action: MIMIC code repo\n",
      "Action Input: renal replacement therapy\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Renal replacement therapy is mentioned in the context as a way to calculate the MELD score. It is used to identify candidates with a creatinine value greater than 4.0 mg/dL, who have received two or more dialysis treatments within the prior week, or who have received 24 hours of continuous veno-venous hemodialysis (CVVHD) within the prior week.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Patients who have received two or more dialysis treatments within the prior week, or who have received 24 hours of continuous veno-venous hemodialysis (CVVHD) within the prior week, can be identified as having received renal replacement therapy in the MIMIC dataset.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Patients who have received two or more dialysis treatments within the prior week, or who have received 24 hours of continuous veno-venous hemodialysis (CVVHD) within the prior week, can be identified as having received renal replacement therapy in the MIMIC dataset.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"How can I determine which patients got renal replacement therapy in the MIMIC dataset?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634f737-d855-41c9-a694-fb63b5dd1a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
